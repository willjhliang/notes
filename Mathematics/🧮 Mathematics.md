The following covers the mathematics background required for [[ğŸ¤– Machine Learning]] and [[ğŸ§  Deep Learning]].

> [!info]
> I'll add core theoretical math here as well sometime in the future, stay tuned!

[[â„¹ï¸ Information Theory]] and [[ğŸª™ Probability Theory]] are two common methods for analyzing and optimizing models. Some basic linear algebra is also useful.
1. [[ğŸ“Œ Norms]] and [[ğŸ“ KL Divergence]] measure the distance between vectors and probability distributions respectively.
2. [[ğŸ¿ Kernels]] measure similarity (analogous to the inverse of distance) between two vectors.
3. [[ğŸ“ Singular Value Decomposition]] decomposes a matrix and is commonly used for dimensionality reduction or compression.
4. [[ğŸ‘ Evidence Lower Bound]] provides a lower bound on intractable probability distributions.